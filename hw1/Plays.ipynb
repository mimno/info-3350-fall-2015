{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART II. This IPython notebook analyzes the plays of William Shakespeare.\n",
    "\n",
    "Review the code, and then answer the questions at the end. Edit the Q/A fields at the end.\n",
    "Some questions will ask you to make changes to code. When you edit a line of code, copy the original and keep it in a comment starting with four hashmarks like this:\n",
    "```\n",
    "#### pi = 4.0\n",
    "pi = 3.14159\n",
    "```\n",
    "\n",
    "Some questions have specific answers, some have multiple good solutions, others are more open-ended.\n",
    "\n",
    "Note that about half of this assignment involves fixing errors in input and curating documents and vocabulary.\n",
    "\n",
    "I downloaded the documents from http://lexically.net/wordsmith/support/shakespeare.html, 9/9/15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import codecs\n",
    "\n",
    "import glob\n",
    "\n",
    "# Tell python we need the natural language toolkit and \n",
    "#  a particular type of tokenizer.\n",
    "import nltk\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "\n",
    "# Counter is a fancy dictionary. It doesn't require \n",
    "#  you to check if a symbol has been counted before.\n",
    "#  You can also add and subtract Counters.\n",
    "from collections import Counter\n",
    "\n",
    "# We want to separate some of the documents as a testing\n",
    "#  set, so we need a way to create random numbers\n",
    "import random\n",
    "\n",
    "# We need the log function\n",
    "import math\n",
    "\n",
    "# here's where we actually make a new tokenizer\n",
    "tokenizer = TreebankWordTokenizer()\n",
    "\n",
    "category_counters = {}\n",
    "\n",
    "plays = []\n",
    "\n",
    "categories = [\"comedies\", \"historical\", \"tragedies\"]\n",
    "\n",
    "all_words = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comedies\n",
      "  plays/comedies/A Midsummer-Night's Dream.txt\n",
      "  plays/comedies/All's Well that Ends Well.txt\n",
      "  plays/comedies/As You Like It.txt\n",
      "  plays/comedies/Cymbeline.txt\n",
      "  plays/comedies/Love's Labour's Lost.txt\n",
      "  plays/comedies/Measure for Measure.txt\n",
      "  plays/comedies/Much Ado About Nothing.txt\n",
      "  plays/comedies/Pericles, Prince of Tyre.txt\n",
      "  plays/comedies/The Comedy of Errors.txt\n",
      "  plays/comedies/The Merchant Of Venice.txt\n",
      "  plays/comedies/The Merry Wives of Windsor.txt\n",
      "  plays/comedies/The Taming of the Shrew.txt\n",
      "  plays/comedies/The Tempest.txt\n",
      "  plays/comedies/The Two Gentlemen of Verona.txt\n",
      "  plays/comedies/The Winter's Tale.txt\n",
      "  plays/comedies/Troilus and Cressida.txt\n",
      "  plays/comedies/Twelfth-Night; or What You Will.txt\n",
      "historical\n",
      "  plays/historical/The Famous History of the Life of King Henry VIII.txt\n",
      "  plays/historical/The First Part of King Henry IV.txt\n",
      "  plays/historical/The First Part of King Henry VI.txt\n",
      "  plays/historical/The Life and Death of King John.txt\n",
      "  plays/historical/The Life of King Henry V.txt\n",
      "  plays/historical/The Second Part of King Henry IV.txt\n",
      "  plays/historical/The Second Part of King Henry VI.txt\n",
      "  plays/historical/The Third Part of King Henry VI.txt\n",
      "  plays/historical/The Tragedy of King Richard II.txt\n",
      "  plays/historical/The Tragedy of King Richard III.txt\n",
      "tragedies\n",
      "  plays/tragedies/Anthony and Cleopatra.txt\n",
      "  plays/tragedies/Coriolanus.txt\n",
      "  plays/tragedies/Hamlet, Prince of Denmark.txt\n",
      "  plays/tragedies/Julius Caesar.txt\n",
      "  plays/tragedies/King Lear.txt\n",
      "  plays/tragedies/Macbeth.txt\n",
      "  plays/tragedies/Othello, the Moor of Venice.txt\n",
      "  plays/tragedies/Romeo And Juliet.txt\n",
      "  plays/tragedies/Timon of Athens.txt\n",
      "  plays/tragedies/Titus Andronicus.txt\n"
     ]
    }
   ],
   "source": [
    "## Read in each folder, printing the folder name\n",
    "for category in categories:\n",
    "    print \"{}\".format(category)\n",
    "        \n",
    "    ## Create an empty counter for the folder's category\n",
    "    category_counters[category] = Counter()\n",
    "        \n",
    "    ## Read in each play, printing the name of the play\n",
    "    for play_name in glob.glob(\"plays/{}/*.txt\".format(category)):\n",
    "        print \"  {}\".format(play_name)\n",
    "        with open(play_name, 'r') as play_file:\n",
    "            tokens = []\n",
    "            for line in play_file:\n",
    "                \n",
    "                # list.extend adds the contents of a list to the end\n",
    "                #  of another list. What would list.append do?\n",
    "                tokens.extend(line.split())\n",
    "\n",
    "            plays.append( { \"title\": play_name, \"category\": category, \"tokens\": tokens } )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did this work? Let's look at the first 10 tokens in the first play."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\xff\\xfe<\\x00',\n",
       " '\\x00S\\x00h\\x00a\\x00k\\x00e\\x00s\\x00p\\x00e\\x00a\\x00r\\x00e\\x00',\n",
       " '\\x00-\\x00-\\x00',\n",
       " '\\x00A\\x00',\n",
       " \"\\x00M\\x00I\\x00D\\x00S\\x00U\\x00M\\x00M\\x00E\\x00R\\x00-\\x00N\\x00I\\x00G\\x00H\\x00T\\x00'\\x00S\\x00\",\n",
       " '\\x00D\\x00R\\x00E\\x00A\\x00M\\x00',\n",
       " '\\x00>\\x00',\n",
       " '\\x00',\n",
       " '\\x00<\\x00',\n",
       " '\\x00f\\x00r\\x00o\\x00m\\x00']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plays[0][\"tokens\"][0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1 [5 pts]:\n",
    "\n",
    "Do these words look good to you? Why or why not?\n",
    "\n",
    "What encoding are the files in? Hint: look at the \"Format\" link in the URL listed at the top of this page.\n",
    "\n",
    "Modify the code that reads the documents to take into account file encoding. \n",
    "\n",
    "# Answer:\n",
    "\n",
    "[write your answer here]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's useful to have an indication of how common a word is. Count the number of plays that contain at least one instance of each word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "play_counts = Counter()\n",
    "for play in plays:\n",
    "    distinct_words = set(play[\"tokens\"])\n",
    "    play_counts.update(distinct_words)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did this work? Let's check a few examples. (Note: you'll need to answer the previous question to get the right output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0, 0)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "play_counts[\"the\"], play_counts[\"Hamlet\"], play_counts[\"whoreson\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove words that only occur in one play."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for play in plays:\n",
    "    play[\"tokens\"] = [token for token in play[\"tokens\"] if play_counts[token] > 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This next cell will remove specific words from all plays. Because I get bored typing lots of quotation marks, I'm writing the stoplist as a single string, which I then split into a list with `.split()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stoplist = set(\"the and of\".split())\n",
    "for play in plays:\n",
    "    play[\"tokens\"] = [token for token in play[\"tokens\"] if token not in stoplist]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now create the category-specific word `Counter()`s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for play in plays:\n",
    "    category_counters[play[\"category\"]].update(play[\"tokens\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the union of the vocabularies, and display the most common words for each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('\\x00', 140501), ('\\x00t\\x00h\\x00e\\x00', 9878), ('\\x00I\\x00', 9405), ('\\x00a\\x00n\\x00d\\x00', 7485), ('\\x00t\\x00o\\x00', 6628), ('\\x00o\\x00f\\x00', 6035), ('\\x00a\\x00', 6033), ('\\x00D\\x00I\\x00R\\x00>\\x00', 5157), ('\\x00y\\x00o\\x00u\\x00', 4644), ('\\x00m\\x00y\\x00', 4518), ('\\x00i\\x00n\\x00', 4082), ('\\x00i\\x00s\\x00', 3657), ('\\x00t\\x00h\\x00a\\x00t\\x00', 3289), ('\\x00n\\x00o\\x00t\\x00', 3132), ('\\x00y\\x00o\\x00u\\x00r\\x00', 2848), ('\\x00w\\x00i\\x00t\\x00h\\x00', 2685), ('\\x00b\\x00e\\x00', 2681), ('\\x00f\\x00o\\x00r\\x00', 2668), ('\\x00<\\x00/\\x00S\\x00T\\x00A\\x00G\\x00E\\x00', 2581), ('\\x00<\\x00S\\x00T\\x00A\\x00G\\x00E\\x00', 2544)]\n",
      "[('\\x00', 92288), ('\\x00t\\x00h\\x00e\\x00', 7709), ('\\x00a\\x00n\\x00d\\x00', 5713), ('\\x00o\\x00f\\x00', 5437), ('\\x00I\\x00', 5031), ('\\x00t\\x00o\\x00', 4588), ('\\x00a\\x00', 3506), ('\\x00D\\x00I\\x00R\\x00>\\x00', 3485), ('\\x00m\\x00y\\x00', 3336), ('\\x00i\\x00n\\x00', 2977), ('\\x00A\\x00n\\x00d\\x00', 2483), ('\\x00t\\x00h\\x00a\\x00t\\x00', 2133), ('\\x00h\\x00i\\x00s\\x00', 2106), ('\\x00w\\x00i\\x00t\\x00h\\x00', 2085), ('\\x00i\\x00s\\x00', 2059), ('\\x00y\\x00o\\x00u\\x00', 1994), ('\\x00b\\x00e\\x00', 1775), ('\\x00n\\x00o\\x00t\\x00', 1773), ('\\x00<\\x00/\\x00S\\x00T\\x00A\\x00G\\x00E\\x00', 1745), ('\\x00<\\x00S\\x00T\\x00A\\x00G\\x00E\\x00', 1741)]\n",
      "[('\\x00', 102710), ('\\x00t\\x00h\\x00e\\x00', 6769), ('\\x00a\\x00n\\x00d\\x00', 5120), ('\\x00I\\x00', 5027), ('\\x00t\\x00o\\x00', 4307), ('\\x00D\\x00I\\x00R\\x00>\\x00', 4084), ('\\x00o\\x00f\\x00', 3954), ('\\x00a\\x00', 3188), ('\\x00m\\x00y\\x00', 2835), ('\\x00i\\x00n\\x00', 2573), ('\\x00y\\x00o\\x00u\\x00', 2496), ('\\x00i\\x00s\\x00', 2133), ('\\x00<\\x00/\\x00S\\x00T\\x00A\\x00G\\x00E\\x00', 2043), ('\\x00<\\x00S\\x00T\\x00A\\x00G\\x00E\\x00', 2025), ('\\x00n\\x00o\\x00t\\x00', 2008), ('\\x00t\\x00h\\x00a\\x00t\\x00', 1984), ('\\x00w\\x00i\\x00t\\x00h\\x00', 1878), ('\\x00A\\x00n\\x00d\\x00', 1835), ('\\x00h\\x00i\\x00s\\x00', 1774), ('\\x00h\\x00a\\x00v\\x00e\\x00', 1572)]\n"
     ]
    }
   ],
   "source": [
    "for category in categories:\n",
    "    print category_counters[category].most_common(20)\n",
    "\n",
    "    all_words = all_words.union(category_counters[category].keys())\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now do a leave-one-out cross-validation experiment on each play. This cell will, for each play, get a log score for each category. I'm then displaying the `exp` (inverse log) of these scores normalized so that the *most likely* category is set to 1.000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_score(sample_tokens, counter, smoothing):\n",
    "    score = 0.0\n",
    "\n",
    "    total = sum(counter.values())\n",
    "\n",
    "    for word in sample_tokens:\n",
    "        score += math.log((counter[word] + smoothing) /\n",
    "                          (total + len(all_words) * smoothing))\n",
    "    return score / len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.000\t0.919\t0.992\tcomedies\tplays/comedies/A Midsummer-Night's Dream.txt\n",
      "1.000\t0.850\t0.963\tcomedies\tplays/comedies/All's Well that Ends Well.txt\n",
      "1.000\t0.903\t0.945\tcomedies\tplays/comedies/As You Like It.txt\n",
      "0.972\t0.905\t1.000\tcomedies\tplays/comedies/Cymbeline.txt\n",
      "1.000\t0.891\t0.951\tcomedies\tplays/comedies/Love's Labour's Lost.txt\n",
      "1.000\t0.835\t0.927\tcomedies\tplays/comedies/Measure for Measure.txt\n",
      "1.000\t0.880\t0.909\tcomedies\tplays/comedies/Much Ado About Nothing.txt\n",
      "1.000\t0.932\t0.998\tcomedies\tplays/comedies/Pericles, Prince of Tyre.txt\n",
      "1.000\t0.893\t0.950\tcomedies\tplays/comedies/The Comedy of Errors.txt\n",
      "1.000\t0.901\t0.971\tcomedies\tplays/comedies/The Merchant Of Venice.txt\n",
      "0.973\t1.000\t0.892\tcomedies\tplays/comedies/The Merry Wives of Windsor.txt\n",
      "1.000\t0.902\t0.965\tcomedies\tplays/comedies/The Taming of the Shrew.txt\n",
      "1.000\t0.898\t0.957\tcomedies\tplays/comedies/The Tempest.txt\n",
      "1.000\t0.861\t0.926\tcomedies\tplays/comedies/The Two Gentlemen of Verona.txt\n",
      "1.000\t0.903\t0.973\tcomedies\tplays/comedies/The Winter's Tale.txt\n",
      "0.984\t0.928\t1.000\tcomedies\tplays/comedies/Troilus and Cressida.txt\n",
      "1.000\t0.815\t0.904\tcomedies\tplays/comedies/Twelfth-Night; or What You Will.txt\n",
      "0.949\t1.000\t0.932\thistorical\tplays/historical/The Famous History of the Life of King Henry VIII.txt\n",
      "0.896\t1.000\t0.866\thistorical\tplays/historical/The First Part of King Henry IV.txt\n",
      "0.822\t1.000\t0.855\thistorical\tplays/historical/The First Part of King Henry VI.txt\n",
      "0.898\t1.000\t0.905\thistorical\tplays/historical/The Life and Death of King John.txt\n",
      "0.839\t1.000\t0.822\thistorical\tplays/historical/The Life of King Henry V.txt\n",
      "0.938\t1.000\t0.838\thistorical\tplays/historical/The Second Part of King Henry IV.txt\n",
      "0.744\t1.000\t0.782\thistorical\tplays/historical/The Second Part of King Henry VI.txt\n",
      "0.685\t1.000\t0.735\thistorical\tplays/historical/The Third Part of King Henry VI.txt\n",
      "0.809\t1.000\t0.840\thistorical\tplays/historical/The Tragedy of King Richard II.txt\n",
      "0.754\t1.000\t0.809\thistorical\tplays/historical/The Tragedy of King Richard III.txt\n",
      "0.932\t0.868\t1.000\ttragedies\tplays/tragedies/Anthony and Cleopatra.txt\n",
      "0.924\t0.884\t1.000\ttragedies\tplays/tragedies/Coriolanus.txt\n",
      "1.000\t0.919\t0.958\ttragedies\tplays/tragedies/Hamlet, Prince of Denmark.txt\n",
      "0.846\t0.820\t1.000\ttragedies\tplays/tragedies/Julius Caesar.txt\n",
      "0.989\t0.965\t1.000\ttragedies\tplays/tragedies/King Lear.txt\n",
      "0.947\t0.953\t1.000\ttragedies\tplays/tragedies/Macbeth.txt\n",
      "1.000\t0.881\t0.961\ttragedies\tplays/tragedies/Othello, the Moor of Venice.txt\n",
      "1.000\t0.930\t0.964\ttragedies\tplays/tragedies/Romeo And Juliet.txt\n",
      "0.973\t0.884\t1.000\ttragedies\tplays/tragedies/Timon of Athens.txt\n",
      "0.960\t0.937\t1.000\ttragedies\tplays/tragedies/Titus Andronicus.txt\n"
     ]
    }
   ],
   "source": [
    "for play in plays:\n",
    "    scores = {}\n",
    "    for category in categories:\n",
    "        tokens = play[\"tokens\"]\n",
    "        if category == play[\"category\"]:\n",
    "            category_counters[category].subtract(tokens)\n",
    "            scores[category] = get_score(tokens, category_counters[category], 1.0)\n",
    "            category_counters[category].update(tokens)\n",
    "        else:\n",
    "            scores[category] = get_score(tokens, category_counters[category], 1.0)\n",
    "\n",
    "    max_score = max(scores.values())\n",
    "    print \"{:0.3f}\\t{:0.3f}\\t{:0.3f}\\t{}\\t{}\".format(math.exp(scores['comedies']-max_score),\n",
    "                                                     math.exp(scores['historical']-max_score),\n",
    "                                                     math.exp(scores['tragedies']-max_score),\n",
    "                                                     play['category'], play['title'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2 [5 pts]: \n",
    "\n",
    "Write in your own words how this leave-one-out cross validation code works. How is it different from the k-fold cross validation in class?\n",
    "\n",
    "# Answer:\n",
    "\n",
    "[write your answer here]\n",
    "\n",
    "\n",
    "# Question 3 [5 pts]: \n",
    "\n",
    "Did the classifier get anything \"wrong\"? Are certain categories \"easier\" than others? We'll explore this in more detail in the next question, but write your guesses now.\n",
    "\n",
    "# Answer: \n",
    "\n",
    "[write your answer here]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def explain(sample_tokens, counter1, counter2, smoothing):\n",
    "    total1 = sum(counter1.values())\n",
    "    total2 = sum(counter2.values())\n",
    "    \n",
    "    term_counts = Counter(sample_tokens)\n",
    "    term_log_ratios = []\n",
    "\n",
    "    for word in term_counts.keys():\n",
    "        score1 = math.log((counter1[word] + smoothing) /\n",
    "             (total1 + len(all_words) * smoothing))\n",
    "        score2 = math.log((counter2[word] + smoothing) /\n",
    "             (total2 + len(all_words) * smoothing))\n",
    "        term_log_ratios.append((word, score1 - score2, term_counts[word]))\n",
    "        \n",
    "    def get_ratio(x):\n",
    "        return x[1] * x[2]\n",
    "    \n",
    "    return sorted(term_log_ratios, key=get_ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we'll ask the classifier to give us the individual word-level scores for all the words that appear in Hamlet. The result will be a list of tuples, one per word, sorted by their \"weight of evidence\" for one class or another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hamlet = plays[-8]  # The 8th from last play\n",
    "\n",
    "category_counters['tragedies'].subtract(hamlet['tokens'])\n",
    "term_scores = explain(hamlet['tokens'], category_counters['tragedies'], category_counters['comedies'], 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words indicating tragedy\n",
      "Odds\tCount\tWord\n",
      "1.124:1\t469\t\u0000D\u0000I\u0000R\u0000>\u0000\n",
      "1.509:1\t102\t\u00001\u0000>\u0000\n",
      "1.437:1\t108\t\u0000o\u0000u\u0000r\u0000\n",
      "41.692:1\t9\t\u0000C\u0000a\u0000s\u0000t\u0000l\u0000e\u0000.\u0000>\u0000\n",
      "4.889:1\t18\t\u0000'\u0000t\u0000\n",
      "1.130:1\t233\t\u0000<\u0000S\u0000T\u0000A\u0000G\u0000E\u0000\n",
      "1.205:1\t148\t\u0000T\u0000h\u0000e\u0000\n",
      "1.123:1\t235\t\u0000<\u0000/\u0000S\u0000T\u0000A\u0000G\u0000E\u0000\n",
      "6.414:1\t14\t\u0000<\u0000G\u0000H\u0000O\u0000S\u0000T\u0000>\u0000\n",
      "6.414:1\t14\t\u0000<\u0000/\u0000G\u0000H\u0000O\u0000S\u0000T\u0000>\u0000\n",
      "1.609:1\t54\t\u0000t\u0000h\u0000e\u0000i\u0000r\u0000\n",
      "1.211:1\t120\t\u0000T\u0000h\u0000a\u0000t\u0000\n",
      "1.515:1\t55\t\u0000O\u0000!\u0000\n",
      "2.049:1\t28\t\u0000l\u0000o\u0000r\u0000d\u0000?\u0000\n",
      "1.656:1\t38\t\u00002\u0000>\u0000\n",
      "1.404:1\t53\t\u0000O\u0000\n",
      "1.158:1\t122\t\u0000T\u0000o\u0000\n",
      "2.813:1\t17\t\u0000n\u0000o\u0000b\u0000l\u0000e\u0000\n",
      "1.235:1\t80\t\u0000t\u0000h\u0000y\u0000\n",
      "1.302:1\t61\t\u0000l\u0000o\u0000r\u0000d\u0000.\u0000\n",
      "1.054:1\t280\t\u0000h\u0000i\u0000s\u0000\n",
      "1.181:1\t82\t\u0000t\u0000h\u0000o\u0000u\u0000\n",
      "3.656:1\t10\t\u0000'\u0000t\u0000.\u0000\n",
      "1.394:1\t36\t\u0000L\u0000e\u0000t\u0000\n",
      "1.158:1\t77\t\u0000W\u0000h\u0000a\u0000t\u0000\n",
      "1.046:1\t245\t\u0000A\u0000n\u0000d\u0000\n",
      "1.734:1\t20\t\u0000G\u0000i\u0000v\u0000e\u0000\n",
      "1.259:1\t47\t\u0000u\u0000s\u0000\n",
      "2.138:1\t14\t\u0000l\u0000o\u0000r\u0000d\u0000!\u0000\n",
      "1.293:1\t39\t\u0000H\u0000e\u0000\n",
      "2.978:1\t9\t\u0000'\u0000t\u0000,\u0000\n",
      "1.191:1\t56\t\u0000I\u0000t\u0000\n",
      "1.466:1\t25\t\u0000<\u00001\u0000%\u0000>\u0000\n",
      "3.248:1\t8\t\u0000h\u0000o\u0000!\u0000\n",
      "1.136:1\t73\t\u0000M\u0000y\u0000\n",
      "3.207:1\t8\t\u0000N\u0000o\u0000r\u0000w\u0000a\u0000y\u0000,\u0000\n",
      "3.207:1\t8\t\u0000e\u0000'\u0000e\u0000n\u0000\n",
      "1.430:1\t25\t\u0000d\u0000e\u0000a\u0000r\u0000\n",
      "1.859:1\t14\t\u0000n\u0000a\u0000t\u0000u\u0000r\u0000e\u0000\n",
      "1.226:1\t42\t\u0000t\u0000h\u0000e\u0000m\u0000\n",
      "1.405:1\t25\t\u0000'\u0000T\u0000i\u0000s\u0000\n",
      "3.207:1\t7\t\u0000G\u0000h\u0000o\u0000s\u0000t\u0000.\u0000>\u0000\n",
      "3.894:1\t6\t\u0000s\u0000w\u0000o\u0000r\u0000d\u0000,\u0000\n",
      "1.435:1\t22\t\u0000d\u0000o\u0000e\u0000s\u0000\n",
      "2.654:1\t8\t\u00003\u0000>\u0000\n",
      "1.453:1\t19\t\u0000<\u00006\u00006\u0000%\u0000>\u0000\n",
      "3.259:1\t6\t\u0000g\u0000e\u0000n\u0000e\u0000r\u0000a\u0000l\u0000\n",
      "4.009:1\t5\t\u0000'\u0000t\u0000?\u0000\n",
      "1.774:1\t12\t\u0000O\u0000u\u0000r\u0000\n",
      "1.239:1\t32\t\u0000W\u0000e\u0000\n",
      "2.344:1\t8\t\u0000'\u0000s\u0000\n",
      "5.479:1\t4\t\u0000<\u0000/\u0000A\u0000L\u0000L\u0000>\u0000\n",
      "5.479:1\t4\t\u0000<\u0000A\u0000L\u0000L\u0000>\u0000\n",
      "1.063:1\t109\t\u0000w\u0000e\u0000\n",
      "9.087:1\t3\t\u0000<\u0000D\u0000i\u0000e\u0000s\u0000.\u0000>\u0000\n",
      "1.810:1\t11\t\u0000e\u0000a\u0000r\u0000t\u0000h\u0000\n",
      "1.107:1\t64\t\u0000F\u0000o\u0000r\u0000\n",
      "1.256:1\t28\t\u0000h\u0000i\u0000m\u0000.\u0000\n",
      "1.452:1\t17\t\u0000s\u0000e\u0000e\u0000n\u0000\n",
      "2.405:1\t7\t\u0000w\u0000i\u0000t\u0000h\u0000i\u0000n\u0000.\u0000>\u0000\n",
      "1.142:1\t46\t\u0000T\u0000h\u0000i\u0000s\u0000\n",
      "4.582:1\t4\t\u0000v\u0000i\u0000o\u0000l\u0000e\u0000n\u0000t\u0000\n",
      "2.703:1\t6\t\u0000f\u0000r\u0000i\u0000e\u0000n\u0000d\u0000s\u0000,\u0000\n",
      "1.804:1\t10\t\u0000m\u0000a\u0000j\u0000e\u0000s\u0000t\u0000y\u0000\n",
      "2.673:1\t6\t\u0000E\u0000n\u0000g\u0000l\u0000a\u0000n\u0000d\u0000\n",
      "2.673:1\t6\t\u0000a\u0000w\u0000h\u0000i\u0000l\u0000e\u0000,\u0000\n",
      "1.443:1\t16\t\u0000<\u00008\u00006\u0000%\u0000>\u0000\n",
      "3.207:1\t5\t\u0000w\u0000a\u0000r\u0000-\u0000l\u0000i\u0000k\u0000e\u0000\n",
      "17.639:1\t2\t\u0000m\u0000u\u0000r\u0000d\u0000e\u0000r\u0000!\u0000\n",
      "1.371:1\t18\t\u0000T\u0000h\u0000e\u0000y\u0000\n",
      "2.551:1\t6\t\u0000S\u0000p\u0000e\u0000a\u0000k\u0000\n",
      "2.539:1\t6\t\u0000d\u0000e\u0000s\u0000p\u0000e\u0000r\u0000a\u0000t\u0000e\u0000\n",
      "2.004:1\t8\t\u0000M\u0000a\u0000k\u0000e\u0000\n",
      "1.228:1\t27\t\u0000u\u0000p\u0000\n",
      "1.531:1\t13\t\u0000h\u0000e\u0000a\u0000v\u0000e\u0000n\u0000,\u0000\n",
      "1.825:1\t9\t\u0000W\u0000h\u0000a\u0000t\u0000!\u0000\n",
      "1.429:1\t15\t\u0000d\u0000e\u0000a\u0000t\u0000h\u0000\n",
      "1.299:1\t20\t\u0000t\u0000h\u0000o\u0000s\u0000e\u0000\n",
      "5.612:1\t3\t\u0000f\u0000o\u0000r\u0000t\u0000u\u0000n\u0000e\u0000'\u0000s\u0000\n",
      "1.678:1\t10\t\u0000W\u0000h\u0000o\u0000s\u0000e\u0000\n",
      "3.608:1\t4\t\u0000h\u0000e\u0000a\u0000l\u0000t\u0000h\u0000\n",
      "1.578:1\t11\t\u0000c\u0000a\u0000u\u0000s\u0000e\u0000\n",
      "1.565:1\t11\t\u0000t\u0000h\u0000e\u0000m\u0000.\u0000\n",
      "1.085:1\t60\t\u0000<\u0000E\u0000n\u0000t\u0000e\u0000r\u0000\n",
      "1.236:1\t23\t\u0000i\u0000'\u0000\n",
      "2.004:1\t7\t\u0000d\u0000e\u0000e\u0000d\u0000\n",
      "1.554:1\t11\t\u0000t\u0000h\u0000i\u0000s\u0000?\u0000\n",
      "1.998:1\t7\t\u0000u\u0000s\u0000.\u0000\n",
      "11.225:1\t2\t\u0000d\u0000a\u0000g\u0000g\u0000e\u0000r\u0000s\u0000\n",
      "117.058:1\t1\t\u0000B\u0000r\u0000u\u0000t\u0000u\u0000s\u0000\n",
      "1.539:1\t11\t\u0000d\u0000e\u0000a\u0000t\u0000h\u0000,\u0000\n",
      "1.283:1\t19\t\u0000<\u00005\u00005\u0000%\u0000>\u0000\n",
      "1.370:1\t15\t\u0000U\u0000p\u0000o\u0000n\u0000\n",
      "4.811:1\t3\t\u0000E\u0000n\u0000g\u0000l\u0000a\u0000n\u0000d\u0000!\u0000\n",
      "1.949:1\t7\t\u0000p\u0000o\u0000w\u0000e\u0000r\u0000\n",
      "3.207:1\t4\t\u0000G\u0000h\u0000o\u0000s\u0000t\u0000\n",
      "3.207:1\t4\t\u0000M\u0000o\u0000t\u0000h\u0000e\u0000r\u0000,\u0000\n",
      "3.207:1\t4\t\u0000u\u0000p\u0000;\u0000\n",
      "2.520:1\t5\t\u0000k\u0000i\u0000n\u0000g\u0000?\u0000\n"
     ]
    }
   ],
   "source": [
    "def log_ratio_to_odds(x):\n",
    "    if x < 0.0:\n",
    "        return \"1:{:.3f}\".format(math.exp(-x))\n",
    "    else:\n",
    "        return \"{:.3f}:1\".format(math.exp(x))\n",
    "\n",
    "print \"Words indicating tragedy\"\n",
    "print \"Odds\\tCount\\tWord\"\n",
    "\n",
    "tragic_words = term_scores[-100:-1]  ## take the end of the list\n",
    "tragic_words.reverse()\n",
    "\n",
    "for word_score in tragic_words:\n",
    "    print \"{}\\t{}\\t{}\".format(log_ratio_to_odds(word_score[1]), word_score[2], word_score[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words indicating comedy\n",
      "Odds\tCount\tWord\n",
      "1:127.219\t102\t\u0000<\u0000K\u0000I\u0000N\u0000G\u0000>\u0000\n",
      "1:127.219\t102\t\u0000<\u0000/\u0000K\u0000I\u0000N\u0000G\u0000>\u0000\n",
      "1:17.461\t69\t\u0000<\u0000Q\u0000U\u0000E\u0000E\u0000N\u0000>\u0000\n",
      "1:17.461\t69\t\u0000<\u0000/\u0000Q\u0000U\u0000E\u0000E\u0000N\u0000>\u0000\n",
      "1:1.375\t453\t\u0000a\u0000\n",
      "1:1.299\t512\t\u0000I\u0000\n",
      "1:1.354\t358\t\u0000y\u0000o\u0000u\u0000\n",
      "1:1.131\t628\t\u0000o\u0000f\u0000\n",
      "1:1.178\t443\t\u0000m\u0000y\u0000\n",
      "1:1.118\t609\t\u0000t\u0000o\u0000\n",
      "1:1.351\t223\t\u0000y\u0000o\u0000u\u0000r\u0000\n",
      "1:1.241\t296\t\u0000i\u0000s\u0000\n",
      "1:1.066\t990\t\u0000t\u0000h\u0000e\u0000\n",
      "1:1.170\t397\t\u0000i\u0000n\u0000\n",
      "1:1.448\t145\t\u0000a\u0000s\u0000\n",
      "1:1.352\t168\t\u0000f\u0000o\u0000r\u0000\n",
      "1:1.205\t268\t\u0000i\u0000t\u0000\n",
      "1:1.388\t136\t\u0000w\u0000i\u0000l\u0000l\u0000\n",
      "1:1.325\t147\t\u0000b\u0000u\u0000t\u0000\n",
      "1:1.232\t195\t\u0000b\u0000e\u0000\n",
      "1:1.170\t232\t\u0000t\u0000h\u0000a\u0000t\u0000\n",
      "1:1.053\t689\t\u0000a\u0000n\u0000d\u0000\n",
      "1:1.591\t70\t\u0000h\u0000e\u0000r\u0000\n",
      "1:1.530\t74\t\u0000y\u0000o\u0000u\u0000,\u0000\n",
      "1:1.115\t257\t\u0000n\u0000o\u0000t\u0000\n",
      "1:1.301\t103\t\u0000s\u0000o\u0000\n",
      "1:1.470\t65\t\u0000i\u0000f\u0000\n",
      "1:1.383\t76\t\u0000o\u0000r\u0000\n",
      "1:1.152\t165\t\u0000h\u0000e\u0000\n",
      "1:1.121\t200\t\u0000t\u0000h\u0000i\u0000s\u0000\n",
      "1:1.246\t100\t\u0000b\u0000y\u0000\n",
      "1:1.157\t138\t\u0000m\u0000e\u0000\n",
      "1:1.945\t30\t\u0000s\u0000i\u0000r\u0000,\u0000\n",
      "1:1.402\t57\t\u0000v\u0000e\u0000r\u0000y\u0000\n",
      "1:1.295\t69\t\u0000w\u0000a\u0000s\u0000\n",
      "1:1.221\t88\t\u0000n\u0000o\u0000\n",
      "1:1.686\t33\t\u0000s\u0000h\u0000e\u0000\n",
      "1:1.280\t66\t\u0000g\u0000o\u0000o\u0000d\u0000\n",
      "1:1.469\t42\t\u0000t\u0000h\u0000e\u0000r\u0000e\u0000\n",
      "1:1.381\t49\t\u0000a\u0000m\u0000\n",
      "1:1.284\t63\t\u0000w\u0000o\u0000u\u0000l\u0000d\u0000\n",
      "1:1.441\t41\t\u0000l\u0000o\u0000v\u0000e\u0000\n",
      "1:2.233\t18\t\u0000p\u0000l\u0000a\u0000y\u0000\n",
      "1:1.762\t25\t\u0000f\u0000a\u0000t\u0000h\u0000e\u0000r\u0000\n",
      "1:1.226\t68\t\u0000l\u0000i\u0000k\u0000e\u0000\n",
      "1:3.326\t11\t\u0000K\u0000i\u0000n\u0000g\u0000,\u0000\n",
      "1:3.742\t10\t\u0000Q\u0000u\u0000e\u0000e\u0000n\u0000,\u0000\n",
      "1:1.338\t45\t\u0000m\u0000u\u0000c\u0000h\u0000\n",
      "1:1.209\t69\t\u0000m\u0000o\u0000r\u0000e\u0000\n",
      "1:6.392\t7\t\u0000k\u0000i\u0000n\u0000g\u0000'\u0000s\u0000\n",
      "1:1.243\t57\t\u0000I\u0000'\u0000l\u0000l\u0000\n",
      "1:1.117\t111\t\u0000w\u0000h\u0000a\u0000t\u0000\n",
      "1:1.837\t20\t\u0000p\u0000r\u0000a\u0000y\u0000\n",
      "1:1.244\t55\t\u0000h\u0000a\u0000t\u0000h\u0000\n",
      "1:2.183\t15\t\u0000G\u0000o\u0000d\u0000\n",
      "1:1.168\t75\t\u0000a\u0000t\u0000\n",
      "1:1.785\t20\t\u0000<\u00003\u00000\u0000%\u0000>\u0000\n",
      "1:1.468\t30\t\u0000h\u0000o\u0000w\u0000\n",
      "1:1.074\t160\t\u0000h\u0000a\u0000v\u0000e\u0000\n",
      "1:1.109\t104\t\u0000s\u0000h\u0000a\u0000l\u0000l\u0000\n",
      "1:1.368\t34\t\u0000m\u0000e\u0000,\u0000\n",
      "1:1.290\t41\t\u0000i\u0000t\u0000,\u0000\n",
      "1:1.469\t27\t\u0000k\u0000i\u0000n\u0000g\u0000\n",
      "1:1.189\t59\t\u0000m\u0000a\u0000y\u0000\n",
      "1:1.225\t50\t\u0000a\u0000n\u0000\n",
      "1:1.756\t18\t\u0000s\u0000w\u0000e\u0000e\u0000t\u0000\n",
      "1:1.288\t39\t\u0000t\u0000h\u0000i\u0000n\u0000k\u0000\n",
      "1:1.344\t33\t\u0000m\u0000a\u0000n\u0000\n",
      "1:2.049\t13\t\u0000i\u0000s\u0000,\u0000\n",
      "1:1.223\t46\t\u0000c\u0000o\u0000m\u0000e\u0000\n",
      "1:6.236\t5\t\u0000f\u0000a\u0000t\u0000\n",
      "1:1.317\t32\t\u0000t\u0000o\u0000o\u0000\n",
      "1:1.267\t37\t\u0000t\u0000h\u0000a\u0000n\u0000\n",
      "1:2.391\t10\t\u0000y\u0000o\u0000u\u0000t\u0000h\u0000\n",
      "1:1.335\t30\t\u0000o\u0000n\u0000e\u0000\n",
      "1:1.448\t23\t\u0000<\u00002\u00001\u0000%\u0000>\u0000\n",
      "1:1.106\t84\t\u0000B\u0000u\u0000t\u0000\n",
      "1:1.366\t27\t\u0000i\u0000t\u0000.\u0000\n",
      "1:1.366\t26\t\u0000B\u0000u\u0000t\u0000,\u0000\n",
      "1:3.118\t7\t\u0000<\u0000/\u0000C\u0000A\u0000P\u0000T\u0000A\u0000I\u0000N\u0000>\u0000\n",
      "1:3.118\t7\t\u0000<\u0000C\u0000A\u0000P\u0000T\u0000A\u0000I\u0000N\u0000>\u0000\n",
      "1:1.070\t118\t\u0000a\u0000r\u0000e\u0000\n",
      "1:1.352\t26\t\u0000W\u0000h\u0000y\u0000,\u0000\n",
      "1:1.746\t14\t\u0000b\u0000e\u0000l\u0000i\u0000e\u0000v\u0000e\u0000\n",
      "1:1.680\t15\t\u0000f\u0000a\u0000i\u0000r\u0000\n",
      "1:2.962\t7\t\u0000d\u0000a\u0000u\u0000g\u0000h\u0000t\u0000e\u0000r\u0000\n",
      "1:1.129\t62\t\u0000A\u0000\n",
      "1:2.546\t8\t\u0000e\u0000x\u0000c\u0000e\u0000l\u0000l\u0000e\u0000n\u0000t\u0000\n",
      "1:2.111\t10\t\u0000e\u0000n\u0000d\u0000\n",
      "1:1.137\t57\t\u0000H\u0000o\u0000w\u0000\n",
      "1:1.339\t25\t\u0000w\u0000e\u0000r\u0000e\u0000\n",
      "1:1.440\t20\t\u0000<\u00005\u00003\u0000%\u0000>\u0000\n",
      "1:1.222\t36\t\u0000t\u0000e\u0000l\u0000l\u0000\n",
      "1:1.660\t14\t\u0000a\u0000n\u0000y\u0000\n",
      "1:1.083\t89\t\u0000a\u0000l\u0000l\u0000\n",
      "1:1.339\t24\t\u0000d\u0000o\u0000t\u0000h\u0000\n",
      "1:1.262\t30\t\u0000m\u0000i\u0000n\u0000e\u0000\n",
      "1:2.644\t7\t\u0000M\u0000a\u0000r\u0000r\u0000y\u0000,\u0000\n",
      "1:1.139\t51\t\u0000Y\u0000o\u0000u\u0000\n",
      "1:1.604\t14\t\u0000y\u0000o\u0000u\u0000n\u0000g\u0000\n"
     ]
    }
   ],
   "source": [
    "comic_words = term_scores[0:100]\n",
    "\n",
    "print \"Words indicating comedy\"\n",
    "print \"Odds\\tCount\\tWord\"\n",
    "for word_score in comic_words:\n",
    "    print \"{}\\t{}\\t{}\".format(log_ratio_to_odds(word_score[1]), word_score[2], word_score[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4 [5 pts]:\n",
    "\n",
    "Are all of these \"words\" actually words? Modify the code that reads the documents to remove (or not record) stage directions. In the answer, describe how you did it. Now re-run this notebook. What changed, in terms of \"correct\" classifications and most significant distinguishing words?\n",
    "\n",
    "# Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5 [5 pts]:\n",
    "\n",
    "Modify the \"stoplist\" string above to remove specific words (your choice). How, if at all, does this affect the classification results and the most significant distinguishing words?\n",
    "\n",
    "# Answer:\n",
    "\n",
    "[write your answer here]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 6 [5 pts]:\n",
    "\n",
    "What does this experiment tell you? Did you learn anything about Shakespeare, classification, drama, or Early Modern English usage? How does the \"evidence\" of the classifier relate to traditional methods of classifying these works? See, for example: https://en.wikipedia.org/wiki/Shakespearean_tragedy.\n",
    "\n",
    "This is an open-ended question. We expect responses of about a page. There is no right answer. A good response will be thoughtful, creative, and grounded in specific examples and counter-examples.\n",
    "\n",
    "# Answer:\n",
    "\n",
    "[write your answer here]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
